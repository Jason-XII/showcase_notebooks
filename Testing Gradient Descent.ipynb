{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaafa0ec-2d55-4352-911a-0592e95f2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import fastbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0783586-1da9-4e30-b967-67d5ae886e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47521471-1cc5-47cd-b618-771649717052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94117d8-e3cd-40f4-abc5-e3957606698d",
   "metadata": {},
   "source": [
    "Yes! It seems like we get a path object. But how do we get real image data for training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c7318f-4ac8-4793-ab4d-54c96602d0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('train'),Path('valid')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.BASE_PATH = data\n",
    "data.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd7d71-e4a0-4fd5-9852-b2a635f769fc",
   "metadata": {},
   "source": [
    "Wow, this way we can make the paths more cleaner. So two folders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a5e0a1-555a-4414-88fb-1bced51af721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787ab1a-f99a-4cc4-a523-b839fecf6854",
   "metadata": {},
   "source": [
    "Only threes and sevens. Of course, this is only a *sample* of the MNIST dataset. So guess I know where to find the images now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36259ae5-6013-4dce-b49b-31e845d8772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0, 249, 253, 245, 126,   0,   0],\n",
       "        [  0,  14, 101, 223, 253, 248, 124,   0,   0,   0],\n",
       "        [166, 239, 253, 253, 253, 187,  30,   0,   0,   0],\n",
       "        [248, 250, 253, 253, 253, 253, 232, 213, 111,   2],\n",
       "        [  0,  43,  98,  98, 208, 253, 253, 253, 253, 187],\n",
       "        [  0,   0,   0,   0,   9,  51, 119, 253, 253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,   1, 183, 253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 182, 253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 249, 253, 253],\n",
       "        [  0,   0,   0,   0,   0,  60, 214, 253, 253, 173]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = [tensor(Image.open(i)) for i in (data/'train'/'3').ls()]\n",
    "threes[1][10:20, 10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e636849-fb9a-4599-984b-aeb6de387eda",
   "metadata": {},
   "source": [
    "Hang there! It's not as easy as I think to write this line of code, because there are some gruesome parts. \n",
    "- First, you cannot just open the images and left them raw in the list, like `[Image.open(i) for i in (data/'train'/'3').ls()]` as I first did so. Writing code like this have many disadvantages. You can't access their data just by opening them. No matter what you do, you must turn them into tensors eventually. \n",
    "- Turning them into tensors is not an easy task. Because a `Tensor` and a `tensor` is very different! Calling the first one gives errors.\n",
    "\n",
    "And now you get all of threes in the training dataset turned into tensors. Great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c7aa9f-741b-4fb0-9e63-0d70689300c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sevens = [tensor(Image.open(i)) for i in (data/'train'/'7').ls()]\n",
    "valid_threes = [tensor(Image.open(i)) for i in (data/'valid'/'3').ls()]\n",
    "valid_sevens = [tensor(Image.open(i)) for i in (data/'valid'/'7').ls()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9323f34-a650-4ea8-b06a-2e0a99378bbb",
   "metadata": {},
   "source": [
    "Now we do this to the other images. But it is hard to miss that the data structure storing the tensors is not a tensor. If we train the model on pure python lists, it will be, well, very slow and discouraging. So what do we do next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d00a91-8c34-4c75-8936-d836bef4fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack(threes)\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89a492-74ce-490a-9b65-181c08c3429b",
   "metadata": {},
   "source": [
    "Ok! We stack the items in the list together to make a huge 3-dimension tensor! We can use the same approach to stack the other lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5caf5c52-2feb-4065-9853-b2c12c41d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sevens = torch.stack(sevens)\n",
    "stacked_vsevens = torch.stack(valid_sevens)\n",
    "stacked_vthrees = torch.stack(valid_threes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a896b8cb-e690-4aa3-a61a-abca816ab103",
   "metadata": {},
   "source": [
    "We haven't done yet! We need to squeeze the picture into a single dimension array of pixels, not a 28x28 sized 2d image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80492c56-64ed-48ff-a2a0-a44994765828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 784])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3 = stacked_threes.view(-1, 28*28)\n",
    "train3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40a2e2-ddc1-47be-87d9-96a49f9b951d",
   "metadata": {},
   "source": [
    "Hopefully that is correct. Now do this to other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4a7ac65-ff68-4dc5-a957-0bfc50323dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train7 = stacked_sevens.view(-1, 28*28)\n",
    "valid3 = stacked_vthrees.view(-1, 28*28)\n",
    "valid7 = stacked_vsevens.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb799f82-52da-4f9d-b1eb-509d89ee9e17",
   "metadata": {},
   "source": [
    "This is still not over! After squeezing the dimensions, we now need to squeeze the value of the images, because all of the values (representing the pixels) are between 0 and 255, and we need all the values between 0 and 1. So we take the actions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f46cda0f-a893-4467-899e-0011ff80c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = stacked_threes.view(-1, 28*28)/255\n",
    "train7 = stacked_sevens.view(-1, 28*28)/255\n",
    "valid3 = stacked_vthrees.view(-1, 28*28)/255\n",
    "valid7 = stacked_vsevens.view(-1, 28*28)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f394a-2039-4cd1-9168-9c17c8a314b0",
   "metadata": {},
   "source": [
    "Now we are all done preparing our data for training! We now put the previous code together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5da29d38-2ed9-401c-b8b1-9eb6423e025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import fastbook\n",
    "\n",
    "data = untar_data(URLs.MNIST_SAMPLE)\n",
    "threes = [tensor(Image.open(i)) for i in (data/'train'/'3').ls()]\n",
    "sevens = [tensor(Image.open(i)) for i in (data/'train'/'7').ls()]\n",
    "valid_threes = [tensor(Image.open(i)) for i in (data/'valid'/'3').ls()]\n",
    "valid_sevens = [tensor(Image.open(i)) for i in (data/'valid'/'7').ls()]\n",
    "stacked_threes = torch.stack(threes)\n",
    "stacked_sevens = torch.stack(sevens)\n",
    "stacked_vsevens = torch.stack(valid_sevens)\n",
    "stacked_vthrees = torch.stack(valid_threes)\n",
    "train3 = stacked_threes.view(-1, 28*28)/255\n",
    "train7 = stacked_sevens.view(-1, 28*28)/255\n",
    "valid3 = stacked_vthrees.view(-1, 28*28)/255\n",
    "valid7 = stacked_vsevens.view(-1, 28*28)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c99df-74ad-4c36-a126-8e67e2dbb644",
   "metadata": {
    "tags": []
   },
   "source": [
    "It's time for us to start building a model.\n",
    "# Parameters, Predictions and Accuracy\n",
    "The first step we need to take is to generate some random parameters. In this case we use a linear model in w\\*x+b style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9b16b0e-7600-4a75-860e-d75468171f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor([0.3143]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.randn(28*28).unsqueeze(1)\n",
    "bias = torch.randn(1)\n",
    "weights.shape, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a782163-8170-4db3-b8c7-5c1072a39103",
   "metadata": {},
   "source": [
    "We use matrix multiplication to classify the pictures. So we need the weights to change shape and have 784 rows instead of 784 columns.\n",
    "\n",
    "Now we do a single prediction to a picture and have a look at its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "553041e5-7e67-4e46-8d3c-81ac4935a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.8016])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train3[1]\n",
    "p@weights+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae02330-ddc6-4f19-aba8-9c665dec9db3",
   "metadata": {},
   "source": [
    "So what does the result mean? We should define what it means, and now we define that if the value if above zero, it means that the machine predicts the image is a 3. Else, it is a 7. And we calculate the accuracy and the loss based on that. Let's write a function to do the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b365744-99ba-4e33-96c5-8722e33c3ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.7097])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(inp, params: tuple):\n",
    "    w, b = params\n",
    "    return inp@w+b\n",
    "params = (weights, bias)\n",
    "predict(p, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf98c38-f0de-4a9a-a5ec-7b55f13ba927",
   "metadata": {},
   "source": [
    "Perfect! After making the first prediction, we need to calculate the loss. But if we want to make the loss more \"countable\", the value of the loss need to be from 0 and 1, not positive infinity or negative infinity. That's when the sigmoid function comes in handy. We modify the `predict` function using sigmoid:\n",
    "> Notice that the function predicts whether a image is a three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "74fa16d9-ecdf-436c-97aa-00a45f87aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(inp, params: tuple):\n",
    "    w, b = params\n",
    "    raw_result = inp@w+b\n",
    "    return torch.sigmoid(raw_result)\n",
    "predict(p, (weights, bias))\n",
    "predict(merged, params).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dea06d-e325-4927-ab1c-e9e11511e778",
   "metadata": {},
   "source": [
    "Great! And now to actually train the model, we need to merge the dataset together and create a set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "541d1521-4a6f-431a-bb4d-0cc9e6c129e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tensor([[1]*len(train3)+[0]*len(train7)]).T\n",
    "merged = torch.concat((train3, train7))\n",
    "merged.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47630c-a04e-4660-86e9-0678b02dab95",
   "metadata": {},
   "source": [
    "We discoverd a new `concat` function to merge tensors. Next we create a function that evaluates the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e920471f-ebb4-414d-a5b4-887e1b17bae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6089)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy(x, y, params):\n",
    "    result = predict(x, params)\n",
    "    raw_acc = (result>0.5).float() == y\n",
    "    return raw_acc.float().mean()\n",
    "get_accuracy(merged, labels, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd0457-a571-4a93-add8-c5b8c472218e",
   "metadata": {},
   "source": [
    "The `get_accuracy` function is the first hard part. We predict the results, and compare the results with 0.5 - if the value is higher than that, it means the machines determines it as a \"3\", then we get the array of 0s and 1s. After that, we use the notation of `result==y` to get if the machine has predicted right. At last we take the average value of the `raw_acc` variable to get the accuracy.\n",
    "\n",
    "Put this part of the code together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9fc99dbf-8229-4384-aeb9-e39b1b823cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tensor([[1]*len(train3)+[0]*len(train7)]).T\n",
    "merged = torch.concat((train3, train7))\n",
    "\n",
    "weights = torch.randn(28*28).unsqueeze(1)\n",
    "bias = torch.randn(1)\n",
    "params = (weights, bias)\n",
    "def predict(inp, params: tuple):\n",
    "    w, b = params\n",
    "    raw_result = inp@w+b\n",
    "    return torch.sigmoid(raw_result)\n",
    "def get_accuracy(x, y, params):\n",
    "    result = predict(x, params)\n",
    "    raw_acc = (result>0.5).float() == y\n",
    "    return raw_acc.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ef171-1024-4ea5-8add-ac0867e24593",
   "metadata": {},
   "source": [
    "# Loss Function and Gradient Descent\n",
    "How do we let the machine improve itself? It all depends on the loss function we are about to define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7a014476-2758-4853-baad-4006e1c02603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3927)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss(x, y, params):\n",
    "    res = predict(x, params)\n",
    "    return torch.where(y==1, 1-res, res).mean()\n",
    "get_loss(merged, labels, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df250b8e-69aa-46de-a228-8dfab97a0160",
   "metadata": {},
   "source": [
    "It seems that we have been doing all right. So now we need to do the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d516777-5809-4184-8245-69b16e5dfbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0103],\n",
      "        [-0.0085],\n",
      "        [-0.0058],\n",
      "        [-0.0035],\n",
      "        [-0.0020],\n",
      "        [-0.0007],\n",
      "        [-0.0002],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]]) tensor([0.0108])\n"
     ]
    }
   ],
   "source": [
    "def calc_grad(x, y, params):\n",
    "    for i in params:\n",
    "        i.requires_grad_()\n",
    "    loss = get_loss(x, y, params)\n",
    "    loss.backward()\n",
    "calc_grad(merged, labels, params)\n",
    "print(weights.grad[100:110], bias.grad)\n",
    "weights.grad = None\n",
    "bias.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6948ea0-c768-412c-baf9-f3fe7c3e2620",
   "metadata": {},
   "source": [
    "Now we have successfully implemented the `calc_grad` method! Notice that we have to clear the gradients after we retrieved them. \n",
    "What's next? We train our model! We feed the model batches of our data and calculate the average gradient, then modify our weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "139dd63d-63ee-4ddd-ab92-0a3763e2629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(list(zip(merged, labels)), batch_size=256, shuffle=True)\n",
    "vdl = DataLoader(list(zip(torch.concat((valid3, valid7)))), tensor([[1]*len(valid3)+[0]*len(valid7)]).T, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66eaa5-1c25-4ae4-bb09-68da6ebb2f2f",
   "metadata": {},
   "source": [
    "After creating our dataloaders, we're able to build a basic training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4510b853-2c4a-4745-b98e-fd45f0378efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0383 0.0382 0.0381 0.0381 0.038 0.0379 0.0378 0.0377 0.0377 0.0376 0.0376 0.0375 0.0374 0.0373 0.0372 0.0372 0.0372 0.0371 0.037 0.0369 0.0369 0.0368 0.0368 0.0367 0.0367 0.0366 0.0365 0.0364 0.0364 0.0363 0.0362 0.0362 0.0361 0.0361 0.036 0.036 0.0359 0.0358 0.0357 0.0356 0.0356 0.0355 0.0355 0.0355 0.0354 0.0354 0.0353 0.0353 0.0352 "
     ]
    }
   ],
   "source": [
    "def train_once(x, y, params, lr=1):\n",
    "    calc_grad(x, y, params)\n",
    "    weights, bias = params\n",
    "    weights.data -= weights.grad * lr\n",
    "    bias.data -= bias.grad * lr\n",
    "    weights.grad = None\n",
    "    bias.grad = None\n",
    "def train_epoch(dl, params, lr=1):\n",
    "    for xi, yi in dl:\n",
    "        train_once(xi, yi, params, lr)\n",
    "        print(round(get_loss(merged, labels, params).item(), 4), end=' ')\n",
    "train_epoch(dl, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52686da0-60b1-40e4-b27c-e1071072f8cd",
   "metadata": {},
   "source": [
    "It is important to use `weights.data` instead of `weights`. Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d873cc60-bcb4-4113-82b4-8efaf91a9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9036785960197449\n",
      "0.9462729692459106\n",
      "0.9561148881912231\n",
      "0.9614391922950745\n",
      "0.9636979699134827\n",
      "0.9664407968521118\n",
      "0.9692642688751221\n",
      "0.9709583520889282\n",
      "0.9731364846229553\n",
      "0.9737818837165833\n"
     ]
    }
   ],
   "source": [
    "labels = tensor([[1]*len(train3)+[0]*len(train7)]).T\n",
    "merged = torch.concat((train3, train7))\n",
    "dl = DataLoader(list(zip(merged, labels)), batch_size=256, shuffle=True)\n",
    "vdl = DataLoader(list(zip(torch.concat((valid3, valid7)))), tensor([[1]*len(valid3)+[0]*len(valid7)]).T, batch_size=256, shuffle=True)\n",
    "weights = torch.randn(28*28).unsqueeze(1)\n",
    "bias = torch.randn(1)\n",
    "params = (weights, bias)\n",
    "\n",
    "def predict(inp, params: tuple):\n",
    "    w, b = params\n",
    "    raw_result = inp@w+b\n",
    "    return torch.sigmoid(raw_result)\n",
    "def get_accuracy(x, y, params):\n",
    "    result = predict(x, params)\n",
    "    raw_acc = (result>0.5).float() == y\n",
    "    return raw_acc.float().mean()\n",
    "def get_loss(x, y, params):\n",
    "    res = predict(x, params)\n",
    "    return torch.where(y==1, 1-res, res).mean()\n",
    "def calc_grad(x, y, params):\n",
    "    for i in params:\n",
    "        i.requires_grad_()\n",
    "    loss = get_loss(x, y, params)\n",
    "    loss.backward()\n",
    "def train_once(x, y, params, lr=1):\n",
    "    calc_grad(x, y, params)\n",
    "    weights, bias = params\n",
    "    weights.data -= weights.grad * lr\n",
    "    bias.data -= bias.grad * lr\n",
    "    weights.grad = None\n",
    "    bias.grad = None\n",
    "def train_epoch(dl, params, lr=1):\n",
    "    for xi, yi in dl:\n",
    "        train_once(xi, yi, params, lr)\n",
    "\n",
    "for i in range(10):\n",
    "    train_epoch(dl, params)\n",
    "    print(get_accuracy(merged, labels, params).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9b11a-a984-44a9-9ec7-7860b3ac25c5",
   "metadata": {},
   "source": [
    "Nearly 98% accuracy!\n",
    "# Refactoring and Reducing the Code\n",
    "All of our functions take (x, y, params) as the input parameters. Seeing from the outside, this is very fustrating because it makes all the functions look the same. We should change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "819d27c1-65ab-4213-9169-9806af1e00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748305678367615\n",
      "0.9758793115615845\n",
      "0.9770894050598145\n",
      "0.9784607887268066\n",
      "0.9795095324516296\n",
      "0.9798322319984436\n",
      "0.9803969264030457\n",
      "0.9810422658920288\n",
      "0.9816069602966309\n",
      "0.9823330044746399\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(raw_prediction, y):\n",
    "    raw_acc = (raw_prediction>0.5).float() == y\n",
    "    return raw_acc.float().mean()\n",
    "def get_loss(raw_prediction, y):\n",
    "    return torch.where(y==1, 1-raw_prediction, raw_prediction).mean()\n",
    "def calc_grad(x, y, params):\n",
    "    for i in params:\n",
    "        i.requires_grad_()\n",
    "    pred = predict(x, params)\n",
    "    loss = get_loss(pred, y)\n",
    "    loss.backward()\n",
    "for i in range(10):\n",
    "    train_epoch(dl, params)\n",
    "    print(get_accuracy(predict(merged, params), labels).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d95211-5277-41a6-a88d-903bbb624b5f",
   "metadata": {},
   "source": [
    "Step 2 is to make the model as a parameter, that is we should take the `predict` function as a parameter. Also the weights are related to the model, so the `params` no longer have to be the function parameter. The dataloader and learning rate should also be a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e7a8d948-6596-4f01-b849-cca35b499f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1.\n",
    "weights = torch.randn(28*28).unsqueeze(1).requires_grad_()\n",
    "bias = torch.randn(1).requires_grad_()\n",
    "params = (weights, bias)\n",
    "\n",
    "def predict(inp):\n",
    "    w, b = params\n",
    "    raw_result = inp@w+b\n",
    "    return raw_result\n",
    "def calc_grad(x, y, model):\n",
    "    pred = torch.sigmoid(model(x))\n",
    "    loss = get_loss(pred, y)\n",
    "    loss.backward()\n",
    "def train_epoch(model):\n",
    "    for xi, yi in dl:\n",
    "        calc_grad(xi, yi, model)\n",
    "        for i in params:\n",
    "            i.data -= i.grad*lr\n",
    "            i.grad = None\n",
    "def validate_model(model):\n",
    "    pred = torch.sigmoid(model(torch.concat((valid3, valid7))))\n",
    "    return round(get_accuracy(pred, tensor([[1]*len(valid3)+[0]*len(valid7)]).T).item(), 4)\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_model(model), end=' ')\n",
    "#train_model(predict, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1620b-4d85-4e39-9e34-846b0bbc0cbe",
   "metadata": {},
   "source": [
    "We also moved the sigmoid from the model function `predict` to the other functions that also use the model. We added the `validate_model` method to know the accuracy of the model on the validation set.\n",
    "\n",
    "So why do we make these changes? That's because it is a standardization process. We can greatly reduce the code by replacing most of the code above with those below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "604c4b33-7754-4971-815d-422a1be5da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701 0.9755 0.9764 0.9769 0.9779 0.9789 0.9789 0.9789 0.9799 0.9799 0.9814 0.9814 0.9814 0.9809 0.9809 0.9823 0.9818 0.9818 0.9828 0.9818 "
     ]
    }
   ],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), 1)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af336e-9064-4459-9e5b-f7ada2306e79",
   "metadata": {},
   "source": [
    "What is this piece of code doing? \n",
    "- Initialize our model using `nn.Linear` instead of defining our own function and weights.\n",
    "- Using a SGD class for modifying the weights and clearing the gradients, replacing the `calc_grad` function.\n",
    "- `train_model` stays the same, but the function `train_epoch` can be simplified by calling the optimizer's methods of `step()` and `zero_grad()`.\n",
    "- The others all stay the same.\n",
    "\n",
    "So the total code will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5309375c-177d-4037-9f1d-f34ae57385a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9681 0.9701 0.9711 0.973 0.9735 0.9735 0.9735 0.975 0.9755 0.9755 0.9755 0.9755 0.9769 0.9755 0.9769 0.9774 0.9774 0.9779 0.9779 0.9779 "
     ]
    }
   ],
   "source": [
    "labels = tensor([[1]*len(train3)+[0]*len(train7)]).T\n",
    "merged = torch.concat((train3, train7))\n",
    "dl = DataLoader(list(zip(merged, labels)), batch_size=256, shuffle=True)\n",
    "vdl = DataLoader(list(zip(torch.concat((valid3, valid7)), tensor([[1]*len(valid3)+[0]*len(valid7)]).T)), batch_size=256, shuffle=True)\n",
    "\n",
    "def get_accuracy(raw_prediction, y):\n",
    "    raw_acc = (raw_prediction.sigmoid()>0.5).float() == y\n",
    "    return raw_acc.float().mean()\n",
    "def get_loss(raw_prediction, y):\n",
    "    raw_prediction = raw_prediction.sigmoid()\n",
    "    return torch.where(y==1, 1-raw_prediction, raw_prediction).mean()\n",
    "def calc_grad(x, y, model):\n",
    "    pred = torch.sigmoid(model(x))\n",
    "    loss = get_loss(pred, y)\n",
    "    loss.backward()\n",
    "def validate_model(model):\n",
    "    pred = model(torch.concat((valid3, valid7)))\n",
    "    return round(get_accuracy(pred, tensor([[1]*len(valid3)+[0]*len(valid7)]).T).item(), 4)\n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_model(model), end=' ')\n",
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), 1)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895da5bc-4ead-41c3-a88d-dcb10f3bd67d",
   "metadata": {},
   "source": [
    "A lot less code than the last part, but we can still do better.\n",
    "# Using a Leaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55e2b642-0573-42b2-b8c7-7cce72a2cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>get_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.041964</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>0.034997</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.032664</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025594</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.026397</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.025955</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = tensor([[1]*len(train3)+[0]*len(train7)]).T\n",
    "merged = torch.concat((train3, train7))\n",
    "dl = DataLoader(list(zip(merged, labels)), batch_size=256, shuffle=True)\n",
    "vdl = DataLoader(list(zip(torch.concat((valid3, valid7)), tensor([[1]*len(valid3)+[0]*len(valid7)]).T)), batch_size=256, shuffle=True)\n",
    "\n",
    "def get_accuracy(raw_prediction, y):\n",
    "    raw_acc = (raw_prediction.sigmoid()>0.5).float() == y\n",
    "    return raw_acc.float().mean()\n",
    "def get_loss(raw_prediction, y):\n",
    "    raw_prediction = raw_prediction.sigmoid()\n",
    "    return torch.where(y==1, 1-raw_prediction, raw_prediction).mean()\n",
    "\n",
    "dls = DataLoaders(dl, vdl)\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=get_loss, metrics=get_accuracy)\n",
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e404033-752b-49ba-bf2f-6de0e1c3ab6e",
   "metadata": {},
   "source": [
    "- `loss_func` and `metrics` get the raw prediction, that is before sigmoid is applied.\n",
    "# Non-linear and Resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7a656c6b-5034-43f1-9a94-fd499d7fb3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>get_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.055009</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.031645</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>0.024563</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016903</td>\n",
       "      <td>0.019853</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.983808</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>0.985280</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1))\n",
    "learn = Learner(dls, model, opt_func=SGD,\n",
    "                loss_func=get_loss, metrics=get_accuracy)\n",
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4030630d-b30b-41fc-baed-ea647a787c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(data)\n",
    "learn = vision_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34804221-fe43-414e-95d2-3c93f750a206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
